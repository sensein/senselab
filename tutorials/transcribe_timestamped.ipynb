{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Transcribe Timestamped Workflow Tutorial\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensein/senselab/blob/main/tutorials/transcribe_timestamped.ipynb)\n",
                "\n",
                "This notebook provides a step-by-step guide on how to use the transcribe_timestamped function to transcribe audio files and obtain timestamped transcriptions.\n",
                "\n",
                "The transcribe_timestamped function processes audio files, transcribes the spoken content, and aligns the transcriptions with the audio to provide timestamps for each segment of text. This can be particularly useful for creating subtitles, indexing audio content, or analyzing speech patterns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import the necessary modules from the Senselab package for audio processing\n",
                "from senselab.audio.data_structures.audio import Audio\n",
                "from senselab.audio.tasks.plotting.plotting import play_audio\n",
                "from senselab.audio.tasks.preprocessing.preprocessing import resample_audios\n",
                "from senselab.audio.workflows.transcribe_timestamped import transcribe_timestamped\n",
                "from senselab.utils.data_structures.language import Language\n",
                "from senselab.utils.data_structures.model import HFModel"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load and Prepare Audio Files\n",
                "Load your audio files into Audio objects."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load an audio file from the specified file path\n",
                "audio = Audio.from_filepath(\"../src/tests/data_for_testing/audio_48khz_mono_16bits.wav\")\n",
                "\n",
                "# Resample the audio to 16kHz to match the model's expected input format\n",
                "audio = resample_audios([audio], 16000)[0]\n",
                "\n",
                "# Play the resampled audio to verify the preprocessing step\n",
                "play_audio(audio)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Transcribe Audio with Timestamps\n",
                "Run the transcription workflow using the transcribe_timestamped function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = HFModel(path_or_uri=\"openai/whisper-tiny\")\n",
                "language = Language(language_code=\"en\")\n",
                "\n",
                "transcriptions = transcribe_timestamped(\n",
                "    audios=[audio],\n",
                "    model=model,\n",
                "    language=language\n",
                ")\n",
                "\n",
                "print(transcriptions)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "senselab-_dRIpWVy-py3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
