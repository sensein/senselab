{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Audio data augmentation tutorial\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensein/senselab/blob/main/tutorials/audio/audio_data_augmentation.ipynb)\n",
                "\n",
                "\n",
                "In this tutorial, we will explore how to augment audio data using both the `audiomentations` and `torch_audiomentations` libraries in combination with the `senselab` package. Data augmentation helps create variations of audio data and can be used, for example to improve the robustness of machine learning models by simulating different real-world conditions."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "First, we should install senselab if it has not already been installed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install 'senselab[audio]'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we start by importing the modules required for the augmentation, plotting, and audio processing tasks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import all necessary modules\n",
                "from audiomentations import Compose as AudiomentationsCompose\n",
                "from audiomentations import Gain as AudiomentationsGain\n",
                "from torch_audiomentations import Compose as TorchAudiomentationsCompose\n",
                "from torch_audiomentations import Gain as TorchAudiomentationsGain\n",
                "\n",
                "from senselab.audio.data_structures import Audio\n",
                "from senselab.audio.tasks.data_augmentation import augment_audios\n",
                "from senselab.audio.tasks.plotting import play_audio, plot_waveform"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, we define the augmentations that we will apply. We will create one augmentation pipeline using the `audiomentations` library and another using the `torch_audiomentations` library.\n",
                "\n",
                "In this example, we will apply a simple `Gain` augmentation, which increases the volumne of the audio.\n",
                "- `min_gain_in_db` and `max_gain_in_db` specify the range of gain (in decibels) to apply to the audio.\n",
                "- p=1.0 ensures that the transformation is applied 100% of the time."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define augmentation\n",
                "augment = AudiomentationsCompose([\n",
                "    AudiomentationsGain(min_gain_in_db=14.99, max_gain_in_db=15, p=1.0)\n",
                "    ])\n",
                "\n",
                "# Define torch-based augmentation\n",
                "torch_augment = TorchAudiomentationsCompose([\n",
                "    TorchAudiomentationsGain(min_gain_in_db=14.99, max_gain_in_db=15, p=1.0)\n",
                "    ])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we load an audio file and perform basic analysis by playing the audio and visualizing its waveform."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load an audio file\n",
                "!mkdir -p tutorial_audio_files\n",
                "!wget -O tutorial_audio_files/audio_48khz_mono_16bits.wav https://github.com/sensein/senselab/raw/main/src/tests/data_for_testing/audio_48khz_mono_16bits.wav\n",
                "\n",
                "audio = Audio(filepath=\"tutorial_audio_files/audio_48khz_mono_16bits.wav\")\n",
                "\n",
                "# Play the audio\n",
                "play_audio(audio)\n",
                "# Plot the log-mel-spectrogram\n",
                "plot_waveform(audio)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will now apply the `audiomentations` augmentation pipeline to the audio and visualize the changes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply the augmentations using the wrapper\n",
                "augmented_audios = augment_audios([audio, audio, audio], augment)\n",
                "# Play the augmented audio\n",
                "play_audio(augmented_audios[0])\n",
                "# Plot the log-mel-spectrogram of the augmented audio\n",
                "plot_waveform(augmented_audios[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Similarly, let's apply the augmentation using the `torch_audiomentations` library."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply the augmentations using the wrapper with torch\n",
                "torch_augmented_audios = augment_audios([audio], torch_augment)\n",
                "# Play the audio augmented with torch\n",
                "play_audio(torch_augmented_audios[0])\n",
                "# Plot the log-mel-spectrogram of the audio augmented with torch\n",
                "plot_waveform(torch_augmented_audios[0])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "senselab-AW7jSiDz-py3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
