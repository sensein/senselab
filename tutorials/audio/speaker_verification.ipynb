{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Speaker Verification\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensein/senselab/blob/main/tutorials/audio/speaker_verification.ipynb)\n",
                "\n",
                "Speaker Verification is a process in which an audio system determines whether a given set of speech samples are from the same speaker. This technology is widely used in various applications such as security systems, authentication processes, and personalized user experiences. The core concept revolves around comparing voice characteristics extracted from speech samples to verify the identity of the speaker.\n",
                "\n",
                "Speaker verification can be done in senselab as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install 'senselab[audio]'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "from senselab.audio.data_structures import Audio\n",
                "from senselab.audio.tasks.plotting import play_audio\n",
                "from senselab.audio.tasks.preprocessing import extract_segments, resample_audios\n",
                "from senselab.audio.tasks.speaker_verification.speaker_verification import verify_speaker\n",
                "\n",
                "# Download an audio file for testing\n",
                "!mkdir -p tutorial_audio_files\n",
                "!wget -O tutorial_audio_files/audio_48khz_mono_16bits.wav https://github.com/sensein/senselab/raw/main/src/tests/data_for_testing/audio_48khz_mono_16bits.wav\n",
                "\n",
                "# Load an audio file from the specified file path into an Audio object.\n",
                "audio = Audio(filepath=\"tutorial_audio_files/audio_48khz_mono_16bits.wav\")\n",
                "\n",
                "# Resample the audio to 16 kHz\n",
                "audio = resample_audios([audio], 16000)[0]\n",
                "\n",
                "# Clip the audio into two different speakers\n",
                "audio_clips = extract_segments([(audio, [(0, 0.8), (0.9, 1.8)])])\n",
                "audio1 = audio_clips[0][0]\n",
                "audio2 = audio_clips[0][1]\n",
                "\n",
                "# Display the audio clips\n",
                "play_audio(audio1)\n",
                "play_audio(audio2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now we can ask senselab to verify whether the two clips are of the same speaker or not. If we give it the same audio clip twice, we should expect a high verification score, and with the two different clips, we should expect a low verification score. Let's see what happens."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# List of audio pairs to compare\n",
                "audio_pairs = [(audio1, audio1), (audio1, audio2)]\n",
                "\n",
                "# Verify if the audios are from the same speaker\n",
                "results = verify_speaker(audio_pairs)\n",
                "\n",
                "# Print the results\n",
                "for score, is_same_speaker in results:\n",
                "    print(f\"Verification Score: {score}, Same Speaker: {is_same_speaker}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The verify_speaker function is designed to accomplish the task of speaker verification using a pre-trained model. Here's a breakdown of how the function achieves this:\n",
                "\n",
                "Input Data: The function takes a list of tuples, where each tuple contains two audio samples to be compared. Each audio sample is represented by an Audio object which includes the signal data and sampling rate.\n",
                "\n",
                "Model and Device Setup: The function uses a pre-trained speaker verification model (SpeechBrainModel). It also selects the appropriate device (CPU or GPU) to run the model efficiently.\n",
                "\n",
                "Sampling Rate Check: The function ensures that the audio samples have a sampling rate of 16kHz, as this is the rate the model was trained on. If the sampling rate does not match, it raises an error.\n",
                "\n",
                "Embedding Extraction: For each pair of audio samples, the function extracts speaker embeddings using the SpeechBrainEmbeddings module. Embeddings are numerical representations that capture the unique characteristics of a speaker's voice.\n",
                "\n",
                "Cosine Similarity Calculation: The function calculates the cosine similarity between the embeddings of the two audio samples. Cosine similarity is a measure of similarity between two vectors, where a higher value indicates greater similarity.\n",
                "\n",
                "Threshold Comparison: The function compares the calculated similarity score against a predefined threshold (default is 0.25). If the score exceeds the threshold, it indicates that the two audio samples are likely from the same speaker.\n",
                "\n",
                "Output: The function returns a list of tuples, each containing the similarity score and a boolean indicating whether the two audio samples are from the same speaker."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "senselab-_dRIpWVy-py3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
