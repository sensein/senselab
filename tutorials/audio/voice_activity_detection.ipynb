{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Voice activity detection (VAD)\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensein/senselab/blob/main/tutorials/audio/voice_activity_detection.ipynb)\n",
                "\n",
                "This tutorial demonstrates how to use the `detect_human_voice_activity_in_audios` function to do voice activity detection.\n",
                "\n",
                "Specifically, will show you how to use the `pyannote/speaker-diarization-3.1` model (https://huggingface.co/pyannote/speaker-diarization-3.1)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary modules\n",
                "from senselab.audio.data_structures import Audio\n",
                "from senselab.audio.tasks.plotting.plotting import play_audio\n",
                "from senselab.audio.tasks.preprocessing import resample_audios\n",
                "from senselab.audio.tasks.voice_activity_detection import detect_human_voice_activity_in_audios\n",
                "from senselab.utils.data_structures import DeviceType, PyannoteAudioModel\n",
                "from senselab.utils.tasks.plotting import plot_segment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize a PyannoteAudioModel for speaker diarization, providing the model's path or URI.\n",
                "model = PyannoteAudioModel(path_or_uri=\"pyannote/speaker-diarization-3.1\")\n",
                "\n",
                "# Specify the device type to be used for processing (CPU in this case).\n",
                "device = DeviceType.CPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load an audio file from the specified file path into an Audio object.\n",
                "audio = Audio.from_filepath(\"../../src/tests/data_for_testing/audio_48khz_mono_16bits.wav\")\n",
                "\n",
                "# Resample the audio to 16kHz, as this is the expected input format for the model.\n",
                "# The resample_audios function returns a list, so we take the first (and only) element.\n",
                "audio = resample_audios([audio], 16000)[0]\n",
                "\n",
                "# Play the resampled audio to verify the preprocessing step was successful.\n",
                "play_audio(audio)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform human voice activity detection on the audio using the specified model and device.\n",
                "# The function returns a list of results, where each element corresponds to an audio segment.\n",
                "results = detect_human_voice_activity_in_audios(audios=[audio], model=model, device=device)\n",
                "\n",
                "# Print the results of the voice activity detection to the console.\n",
                "print(results)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the first segment of the detected human voice activity for visualization.\n",
                "plot_segment(results[0])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "senselab-lOUhtavG-py3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
