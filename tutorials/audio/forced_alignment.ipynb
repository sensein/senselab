{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "5593d473",
            "metadata": {},
            "source": [
                "# Forced Alignment\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensein/senselab/blob/main/tutorials/audio/forced_alignment.ipynb)\n",
                "\n",
                "Forced alignment matches parts of speech in an orthographic transcription to timestamps in a corresponding audio file. This enables annotation of transcriptions for large-scale audio datasets. \n",
                "\n",
                "Forced alignment can be done in senselab as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "109f39ed",
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install 'senselab[audio]'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3667eeb8",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import platform\n",
                "\n",
                "from senselab.audio.data_structures import Audio\n",
                "from senselab.audio.tasks.plotting import play_audio\n",
                "from senselab.audio.tasks.preprocessing import resample_audios\n",
                "\n",
                "# Download an audio file for testing\n",
                "os.makedirs(\"tutorial_audio_files\", exist_ok=True)\n",
                "url = \"https://github.com/sensein/senselab/raw/main/src/tests/data_for_testing/audio_48khz_mono_16bits.wav\"\n",
                "filepath = \"tutorial_audio_files/audio_48khz_mono_16bits.wav\"\n",
                "\n",
                "if platform.system() == \"Linux\":\n",
                "    os.system(f\"wget -O {filepath} {url}\")\n",
                "elif platform.system() == \"Darwin\":\n",
                "    os.system(f\"curl -L -o {filepath} {url}\")\n",
                "else:\n",
                "    raise RuntimeError(\"Unsupported OS\")\n",
                "\n",
                "# Load the audio file from the specified file path as an Audio object.\n",
                "audio = Audio.from_filepath(\"tutorial_audio_files/audio_48khz_mono_16bits.wav\")\n",
                "\n",
                "# Resample the audio to 16 kHz\n",
                "audio = resample_audios([audio], 16000)[0]\n",
                "\n",
                "# Display audio playback button\n",
                "play_audio(audio)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ce97fdd9",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "from senselab.utils.data_structures.model import HFModel\n",
                "from senselab.audio.tasks.speech_to_text.api import transcribe_audios\n",
                "from senselab.audio.tasks.forced_alignment.forced_alignment import align_transcriptions\n",
                "\n",
                "# Load a transcription model\n",
                "whisper_tiny = HFModel(path_or_uri=\"openai/whisper-tiny\")\n",
                "\n",
                "# Transcribe the audio file\n",
                "transcription = transcribe_audios(audios=[audio], model=whisper_tiny)[0]\n",
                "\n",
                "# Align the transcription to the audio waveform\n",
                "aligned_transcription = align_transcriptions([(audio, transcription)])\n",
                "\n",
                "# Print the aligned sentences\n",
                "for aligned_sentence in aligned_transcription[0]:\n",
                "    print(aligned_sentence)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9c1758b7",
            "metadata": {},
            "source": [
                "Senselab's implementation of forced alignment can return alignments at four levels of granularity: utterance, sentence, word, or character. Sentence alignments are always included. Here are examples that include each of these:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0ad7e65b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Utterance and sentence:\n",
                "levels_to_keep = {\"utterance\": True, \"word\": False, \"char\": False}\n",
                "aligned_transcription = align_transcriptions([(audio, transcription)], levels_to_keep=levels_to_keep)\n",
                "print(aligned_transcription)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "senselab",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
