{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Speaker diarization\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensein/senselab/blob/main/tutorials/audio/speaker_diarization.ipynb)\n",
                "\n",
                "This tutorial demonstrates how to use the `diarize_audios` function to perform speaker diarization on some audio files, which means to segment the audio into multiple speakers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install senselab['audio']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary modules\n",
                "from senselab.audio.data_structures import Audio\n",
                "from senselab.audio.tasks.plotting.plotting import play_audio\n",
                "from senselab.audio.tasks.preprocessing import resample_audios\n",
                "from senselab.audio.tasks.speaker_diarization import diarize_audios\n",
                "from senselab.utils.data_structures import DeviceType, PyannoteAudioModel\n",
                "from senselab.utils.tasks.plotting import plot_segment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize a PyannoteAudioModel for speaker diarization, providing the model's path or URI.\n",
                "model = PyannoteAudioModel(path_or_uri=\"pyannote/speaker-diarization-3.1\")\n",
                "\n",
                "# Specify the device type to be used for processing (CPU in this case).\n",
                "device = DeviceType.CPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load an audio file from the specified file path into an Audio object.\n",
                "!mkdir -p tutorial_audio_files\n",
                "!wget -O tutorial_audio_files/audio_48khz_mono_16bits.wav https://github.com/sensein/senselab/raw/main/src/tests/data_for_testing/audio_48khz_mono_16bits.wav\n",
                "\n",
                "audio = Audio(filepath=\"tutorial_audio_files/audio_48khz_mono_16bits.wav\")\n",
                "\n",
                "# Resample the audio to 16kHz, as this is the expected input format for the model.\n",
                "# The resample_audios function returns a list, so we take the first (and only) element.\n",
                "audio = resample_audios([audio], 16000)[0]\n",
                "\n",
                "# Play the resampled audio to verify the preprocessing step was successful.\n",
                "play_audio(audio)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform speaker diarization on the audio using the specified model and device.\n",
                "# The function returns a list of results, where each element corresponds to an audio segment.\n",
                "results = diarize_audios(audios=[audio], model=model, device=device)\n",
                "\n",
                "# Print the results of speaker diarization to the console.\n",
                "print(results)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the detected speakers for visualization.\n",
                "plot_segment(results[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Ehm wait**. In the audio, we can hear four speakers, but the speaker diarization results indicate only two speakers. Why is this happening?\n",
                "\n",
                "Unfortunately, the model is not perfect and can make mistakes. We can try adjusting the parameters by setting `num_speakers=4`, `min_speakers=4`, and `max_speakers=4` to force the model to recognize four speakers. However, this approach doesn't always work as expected."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "senselab-lOUhtavG-py3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
